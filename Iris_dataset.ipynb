{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGwy3ISQlvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu #install tensorflow 2.0 (mandatory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEQL-HpMPcnb",
        "colab_type": "code",
        "outputId": "3f81dca0-11f2-4799-bc4e-0108048aa289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrpbMGV0Nmz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# Labels are specifically one hot encoded\n",
        "# because of the weird behaviour I encountered with SparceCategoricalCrossentropy+NN backprop optimization\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split the data for training and testing\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gcSvtOGTHUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adds sampled normal distribution noise to the weight matrices\n",
        "def pick_neighbour(weights):\n",
        "  w_array = np.array(weights[0])\n",
        "  b_array = np.array(weights[1])\n",
        "\n",
        "  # Select a neighbour model by sampling normal distribution and adding results to weights\n",
        "  return [w_array+np.random.normal(size=w_array.shape),b_array+np.random.normal(size=b_array.shape)] \n",
        "\n",
        "# Cross entropy loss  \n",
        "def iris_loss(y_pred,y_true):\n",
        " return log_loss(y_true,y_pred)\n",
        "\n",
        "def p_star(h,T):\n",
        "  return np.exp(-h/T)\n",
        "\n",
        "# Model training using simulated annealing\n",
        "def train_sa_iris(k_max = 500,annealing_rate = 0.95, decay_freq=10, min_T = 0.1):\n",
        "  \n",
        "  # Define neighbour and main models\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.sigmoid, input_shape=(4,)), \n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.sigmoid),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  neighbour_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.sigmoid, input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.sigmoid),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  \n",
        "  #Init temperature with current model loss\n",
        "  T = iris_loss(model.predict(x_train),y_train)\n",
        "  \n",
        "  losses = []\n",
        "\n",
        "  start = time.time()\n",
        "  for k in range(k_max):\n",
        "\n",
        "    #Select neighbour using normal distribution\n",
        "    for i,l in enumerate(model.layers):\n",
        "      new_weights = pick_neighbour(l.get_weights())\n",
        "      neighbour_model.get_layer(index=i).set_weights(new_weights)\n",
        "    \n",
        "    #Calculate losses for current and neighbour models\n",
        "    preds = model.predict(x_train)\n",
        "    neighbour_preds = neighbour_model.predict(x_train)\n",
        "    val_preds = model.predict(x_test)\n",
        "\n",
        "    model_loss = iris_loss(preds,y_train)\n",
        "    neighbour_loss = iris_loss(neighbour_preds,y_train)\n",
        "    val_loss = iris_loss(val_preds,y_test)\n",
        "\n",
        "    #Save current loss value for visualization\n",
        "    losses.append(val_loss)\n",
        "\n",
        "    #Evaluate p* values for both models and sample value from uniform distribution \n",
        "    p_model = p_star(model_loss,T)\n",
        "    p_neighbour = p_star(neighbour_loss,T)\n",
        "\n",
        "    alpha = p_neighbour/p_model\n",
        "    uniform_sample = np.random.uniform(size=1)\n",
        "\n",
        "    # Update current model weights with neighbour's weights in case if the results improved\n",
        "    # or if not do so with probability alpha\n",
        "    if uniform_sample<=alpha or model_loss>neighbour_loss:\n",
        "      model.set_weights(neighbour_model.get_weights())\n",
        "    \n",
        "    # Training parameters printing for testing\n",
        "    if k%100==0:\n",
        "      accuracy = accuracy_score(np.argmax(y_train,axis=1),np.argmax(preds,axis=1))\n",
        "      print(\"K {},Accuracy: {}, Loss current:{} neighbour:{}, validation_loss {}, p_model {}, p_neighbour {}, alpha {}\".format(k,accuracy,model_loss,neighbour_loss,val_loss,p_model, p_neighbour, alpha))\n",
        "\n",
        "    # Update temperature every decay_freq iterations\n",
        "    if k%decay_freq==0:\n",
        "      T=T*annealing_rate\n",
        "    \n",
        "    # Terminate training process if T value exceeded min_T\n",
        "    if T<min_T:\n",
        "      break\n",
        "\n",
        "  end = time.time()\n",
        "  print(\"Time passed {} seconds\".format(end-start))\n",
        "  # Print losses\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('iteration')\n",
        "  plt.suptitle('Annealing rate {}'.format(annealing_rate))\n",
        "  plt.plot(losses)\n",
        "\n",
        "\n",
        "# Model training using backpropagation\n",
        "def train_sgd_iris(epochs):\n",
        "  # Define the model with the same parameters as SA model\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.sigmoid, input_shape=(4,)), \n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.sigmoid),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam')\n",
        "  \n",
        "  start = time.time()\n",
        "  history = model.fit(x_train,y_train,epochs=epochs ,batch_size=64 ,validation_data=(x_test, y_test))\n",
        "  end = time.time()\n",
        "  print(\"Time passed {} seconds\".format(end-start))\n",
        "  # Print losses\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('iteration')\n",
        "  plt.suptitle('SGD')\n",
        "  plt.plot(history.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWpOIgwrGbeX",
        "colab_type": "code",
        "outputId": "d873eb6a-d868-4bfb-a2e3-8e68c077b47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_sgd_iris(epochs=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/1000\n",
            "120/120 [==============================] - 1s 10ms/sample - loss: 1.1291 - val_loss: 1.1326\n",
            "Epoch 2/1000\n",
            "120/120 [==============================] - 0s 107us/sample - loss: 1.1166 - val_loss: 1.1214\n",
            "Epoch 3/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 1.1085 - val_loss: 1.1115\n",
            "Epoch 4/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 1.1002 - val_loss: 1.1038\n",
            "Epoch 5/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 1.0958 - val_loss: 1.0969\n",
            "Epoch 6/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 1.0905 - val_loss: 1.0912\n",
            "Epoch 7/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 1.0886 - val_loss: 1.0861\n",
            "Epoch 8/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 1.0851 - val_loss: 1.0818\n",
            "Epoch 9/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 1.0815 - val_loss: 1.0782\n",
            "Epoch 10/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 1.0790 - val_loss: 1.0747\n",
            "Epoch 11/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 1.0758 - val_loss: 1.0716\n",
            "Epoch 12/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 1.0725 - val_loss: 1.0685\n",
            "Epoch 13/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 1.0692 - val_loss: 1.0654\n",
            "Epoch 14/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 1.0658 - val_loss: 1.0620\n",
            "Epoch 15/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 1.0623 - val_loss: 1.0588\n",
            "Epoch 16/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 1.0584 - val_loss: 1.0553\n",
            "Epoch 17/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 1.0553 - val_loss: 1.0521\n",
            "Epoch 18/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 1.0511 - val_loss: 1.0484\n",
            "Epoch 19/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 1.0475 - val_loss: 1.0445\n",
            "Epoch 20/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 1.0437 - val_loss: 1.0405\n",
            "Epoch 21/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 1.0396 - val_loss: 1.0364\n",
            "Epoch 22/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 1.0357 - val_loss: 1.0323\n",
            "Epoch 23/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 1.0318 - val_loss: 1.0276\n",
            "Epoch 24/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 1.0278 - val_loss: 1.0226\n",
            "Epoch 25/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 1.0233 - val_loss: 1.0178\n",
            "Epoch 26/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 1.0188 - val_loss: 1.0131\n",
            "Epoch 27/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 1.0144 - val_loss: 1.0080\n",
            "Epoch 28/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 1.0098 - val_loss: 1.0031\n",
            "Epoch 29/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 1.0053 - val_loss: 0.9983\n",
            "Epoch 30/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 1.0004 - val_loss: 0.9929\n",
            "Epoch 31/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.9952 - val_loss: 0.9877\n",
            "Epoch 32/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.9904 - val_loss: 0.9821\n",
            "Epoch 33/1000\n",
            "120/120 [==============================] - 0s 65us/sample - loss: 0.9850 - val_loss: 0.9769\n",
            "Epoch 34/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.9795 - val_loss: 0.9712\n",
            "Epoch 35/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.9740 - val_loss: 0.9654\n",
            "Epoch 36/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.9687 - val_loss: 0.9591\n",
            "Epoch 37/1000\n",
            "120/120 [==============================] - 0s 64us/sample - loss: 0.9627 - val_loss: 0.9531\n",
            "Epoch 38/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.9565 - val_loss: 0.9469\n",
            "Epoch 39/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.9503 - val_loss: 0.9403\n",
            "Epoch 40/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.9439 - val_loss: 0.9336\n",
            "Epoch 41/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.9376 - val_loss: 0.9266\n",
            "Epoch 42/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.9307 - val_loss: 0.9193\n",
            "Epoch 43/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.9240 - val_loss: 0.9120\n",
            "Epoch 44/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.9173 - val_loss: 0.9041\n",
            "Epoch 45/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.9098 - val_loss: 0.8966\n",
            "Epoch 46/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.9024 - val_loss: 0.8888\n",
            "Epoch 47/1000\n",
            "120/120 [==============================] - 0s 119us/sample - loss: 0.8950 - val_loss: 0.8807\n",
            "Epoch 48/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.8873 - val_loss: 0.8726\n",
            "Epoch 49/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.8797 - val_loss: 0.8646\n",
            "Epoch 50/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.8716 - val_loss: 0.8564\n",
            "Epoch 51/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.8640 - val_loss: 0.8479\n",
            "Epoch 52/1000\n",
            "120/120 [==============================] - 0s 107us/sample - loss: 0.8556 - val_loss: 0.8397\n",
            "Epoch 53/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.8474 - val_loss: 0.8315\n",
            "Epoch 54/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.8392 - val_loss: 0.8231\n",
            "Epoch 55/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.8312 - val_loss: 0.8145\n",
            "Epoch 56/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.8226 - val_loss: 0.8059\n",
            "Epoch 57/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.8143 - val_loss: 0.7972\n",
            "Epoch 58/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.8057 - val_loss: 0.7883\n",
            "Epoch 59/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.7970 - val_loss: 0.7795\n",
            "Epoch 60/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.7884 - val_loss: 0.7707\n",
            "Epoch 61/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.7795 - val_loss: 0.7616\n",
            "Epoch 62/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.7711 - val_loss: 0.7529\n",
            "Epoch 63/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.7619 - val_loss: 0.7436\n",
            "Epoch 64/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.7532 - val_loss: 0.7344\n",
            "Epoch 65/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.7447 - val_loss: 0.7250\n",
            "Epoch 66/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.7356 - val_loss: 0.7159\n",
            "Epoch 67/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.7268 - val_loss: 0.7070\n",
            "Epoch 68/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.7181 - val_loss: 0.6982\n",
            "Epoch 69/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.7097 - val_loss: 0.6897\n",
            "Epoch 70/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.7006 - val_loss: 0.6810\n",
            "Epoch 71/1000\n",
            "120/120 [==============================] - 0s 185us/sample - loss: 0.6921 - val_loss: 0.6725\n",
            "Epoch 72/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.6841 - val_loss: 0.6637\n",
            "Epoch 73/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.6750 - val_loss: 0.6555\n",
            "Epoch 74/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.6668 - val_loss: 0.6475\n",
            "Epoch 75/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.6585 - val_loss: 0.6394\n",
            "Epoch 76/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.6504 - val_loss: 0.6314\n",
            "Epoch 77/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.6423 - val_loss: 0.6235\n",
            "Epoch 78/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.6344 - val_loss: 0.6156\n",
            "Epoch 79/1000\n",
            "120/120 [==============================] - 0s 109us/sample - loss: 0.6267 - val_loss: 0.6077\n",
            "Epoch 80/1000\n",
            "120/120 [==============================] - 0s 106us/sample - loss: 0.6189 - val_loss: 0.6003\n",
            "Epoch 81/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.6116 - val_loss: 0.5931\n",
            "Epoch 82/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.6040 - val_loss: 0.5857\n",
            "Epoch 83/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.5967 - val_loss: 0.5785\n",
            "Epoch 84/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.5897 - val_loss: 0.5714\n",
            "Epoch 85/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.5829 - val_loss: 0.5646\n",
            "Epoch 86/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.5760 - val_loss: 0.5581\n",
            "Epoch 87/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.5694 - val_loss: 0.5517\n",
            "Epoch 88/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.5629 - val_loss: 0.5454\n",
            "Epoch 89/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.5566 - val_loss: 0.5394\n",
            "Epoch 90/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.5505 - val_loss: 0.5332\n",
            "Epoch 91/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.5445 - val_loss: 0.5273\n",
            "Epoch 92/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.5385 - val_loss: 0.5217\n",
            "Epoch 93/1000\n",
            "120/120 [==============================] - 0s 104us/sample - loss: 0.5328 - val_loss: 0.5163\n",
            "Epoch 94/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.5272 - val_loss: 0.5111\n",
            "Epoch 95/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.5219 - val_loss: 0.5062\n",
            "Epoch 96/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.5171 - val_loss: 0.5009\n",
            "Epoch 97/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.5113 - val_loss: 0.4961\n",
            "Epoch 98/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.5062 - val_loss: 0.4915\n",
            "Epoch 99/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.5013 - val_loss: 0.4871\n",
            "Epoch 100/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.4967 - val_loss: 0.4827\n",
            "Epoch 101/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.4920 - val_loss: 0.4780\n",
            "Epoch 102/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.4874 - val_loss: 0.4735\n",
            "Epoch 103/1000\n",
            "120/120 [==============================] - 0s 117us/sample - loss: 0.4829 - val_loss: 0.4692\n",
            "Epoch 104/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.4786 - val_loss: 0.4647\n",
            "Epoch 105/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.4742 - val_loss: 0.4606\n",
            "Epoch 106/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.4701 - val_loss: 0.4563\n",
            "Epoch 107/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.4658 - val_loss: 0.4523\n",
            "Epoch 108/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.4618 - val_loss: 0.4485\n",
            "Epoch 109/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.4579 - val_loss: 0.4447\n",
            "Epoch 110/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.4540 - val_loss: 0.4409\n",
            "Epoch 111/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.4502 - val_loss: 0.4371\n",
            "Epoch 112/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.4464 - val_loss: 0.4334\n",
            "Epoch 113/1000\n",
            "120/120 [==============================] - 0s 116us/sample - loss: 0.4431 - val_loss: 0.4301\n",
            "Epoch 114/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.4390 - val_loss: 0.4265\n",
            "Epoch 115/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.4357 - val_loss: 0.4228\n",
            "Epoch 116/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.4320 - val_loss: 0.4194\n",
            "Epoch 117/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.4287 - val_loss: 0.4163\n",
            "Epoch 118/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.4251 - val_loss: 0.4130\n",
            "Epoch 119/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.4217 - val_loss: 0.4098\n",
            "Epoch 120/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.4184 - val_loss: 0.4065\n",
            "Epoch 121/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.4151 - val_loss: 0.4032\n",
            "Epoch 122/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.4118 - val_loss: 0.3999\n",
            "Epoch 123/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.4085 - val_loss: 0.3967\n",
            "Epoch 124/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.4054 - val_loss: 0.3935\n",
            "Epoch 125/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.4023 - val_loss: 0.3903\n",
            "Epoch 126/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.3991 - val_loss: 0.3872\n",
            "Epoch 127/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.3960 - val_loss: 0.3841\n",
            "Epoch 128/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.3929 - val_loss: 0.3813\n",
            "Epoch 129/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.3899 - val_loss: 0.3784\n",
            "Epoch 130/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.3870 - val_loss: 0.3757\n",
            "Epoch 131/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.3838 - val_loss: 0.3727\n",
            "Epoch 132/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.3809 - val_loss: 0.3697\n",
            "Epoch 133/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.3779 - val_loss: 0.3669\n",
            "Epoch 134/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.3749 - val_loss: 0.3640\n",
            "Epoch 135/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.3720 - val_loss: 0.3611\n",
            "Epoch 136/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.3692 - val_loss: 0.3584\n",
            "Epoch 137/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.3665 - val_loss: 0.3554\n",
            "Epoch 138/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.3635 - val_loss: 0.3525\n",
            "Epoch 139/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.3605 - val_loss: 0.3498\n",
            "Epoch 140/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.3577 - val_loss: 0.3472\n",
            "Epoch 141/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.3557 - val_loss: 0.3447\n",
            "Epoch 142/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.3521 - val_loss: 0.3419\n",
            "Epoch 143/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.3495 - val_loss: 0.3390\n",
            "Epoch 144/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.3472 - val_loss: 0.3365\n",
            "Epoch 145/1000\n",
            "120/120 [==============================] - 0s 109us/sample - loss: 0.3440 - val_loss: 0.3338\n",
            "Epoch 146/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.3413 - val_loss: 0.3310\n",
            "Epoch 147/1000\n",
            "120/120 [==============================] - 0s 113us/sample - loss: 0.3385 - val_loss: 0.3283\n",
            "Epoch 148/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.3361 - val_loss: 0.3257\n",
            "Epoch 149/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.3335 - val_loss: 0.3231\n",
            "Epoch 150/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.3307 - val_loss: 0.3205\n",
            "Epoch 151/1000\n",
            "120/120 [==============================] - 0s 132us/sample - loss: 0.3281 - val_loss: 0.3180\n",
            "Epoch 152/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.3263 - val_loss: 0.3156\n",
            "Epoch 153/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.3230 - val_loss: 0.3130\n",
            "Epoch 154/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.3204 - val_loss: 0.3105\n",
            "Epoch 155/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.3179 - val_loss: 0.3080\n",
            "Epoch 156/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.3154 - val_loss: 0.3055\n",
            "Epoch 157/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.3129 - val_loss: 0.3031\n",
            "Epoch 158/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.3105 - val_loss: 0.3006\n",
            "Epoch 159/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.3079 - val_loss: 0.2983\n",
            "Epoch 160/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.3058 - val_loss: 0.2960\n",
            "Epoch 161/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.3031 - val_loss: 0.2936\n",
            "Epoch 162/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.3006 - val_loss: 0.2912\n",
            "Epoch 163/1000\n",
            "120/120 [==============================] - 0s 121us/sample - loss: 0.2982 - val_loss: 0.2888\n",
            "Epoch 164/1000\n",
            "120/120 [==============================] - 0s 136us/sample - loss: 0.2958 - val_loss: 0.2865\n",
            "Epoch 165/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.2934 - val_loss: 0.2841\n",
            "Epoch 166/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.2911 - val_loss: 0.2818\n",
            "Epoch 167/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.2888 - val_loss: 0.2796\n",
            "Epoch 168/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.2864 - val_loss: 0.2773\n",
            "Epoch 169/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.2847 - val_loss: 0.2752\n",
            "Epoch 170/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.2818 - val_loss: 0.2729\n",
            "Epoch 171/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.2800 - val_loss: 0.2707\n",
            "Epoch 172/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.2774 - val_loss: 0.2684\n",
            "Epoch 173/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.2750 - val_loss: 0.2663\n",
            "Epoch 174/1000\n",
            "120/120 [==============================] - 0s 106us/sample - loss: 0.2729 - val_loss: 0.2641\n",
            "Epoch 175/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.2706 - val_loss: 0.2620\n",
            "Epoch 176/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.2684 - val_loss: 0.2598\n",
            "Epoch 177/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.2662 - val_loss: 0.2577\n",
            "Epoch 178/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.2642 - val_loss: 0.2556\n",
            "Epoch 179/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.2620 - val_loss: 0.2535\n",
            "Epoch 180/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.2599 - val_loss: 0.2515\n",
            "Epoch 181/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.2578 - val_loss: 0.2494\n",
            "Epoch 182/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.2558 - val_loss: 0.2474\n",
            "Epoch 183/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.2537 - val_loss: 0.2454\n",
            "Epoch 184/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.2517 - val_loss: 0.2435\n",
            "Epoch 185/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.2495 - val_loss: 0.2415\n",
            "Epoch 186/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.2476 - val_loss: 0.2396\n",
            "Epoch 187/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.2455 - val_loss: 0.2376\n",
            "Epoch 188/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.2436 - val_loss: 0.2357\n",
            "Epoch 189/1000\n",
            "120/120 [==============================] - 0s 99us/sample - loss: 0.2418 - val_loss: 0.2339\n",
            "Epoch 190/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.2397 - val_loss: 0.2320\n",
            "Epoch 191/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.2377 - val_loss: 0.2301\n",
            "Epoch 192/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.2359 - val_loss: 0.2283\n",
            "Epoch 193/1000\n",
            "120/120 [==============================] - 0s 104us/sample - loss: 0.2340 - val_loss: 0.2265\n",
            "Epoch 194/1000\n",
            "120/120 [==============================] - 0s 115us/sample - loss: 0.2322 - val_loss: 0.2246\n",
            "Epoch 195/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.2303 - val_loss: 0.2227\n",
            "Epoch 196/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.2284 - val_loss: 0.2209\n",
            "Epoch 197/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.2265 - val_loss: 0.2191\n",
            "Epoch 198/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.2248 - val_loss: 0.2173\n",
            "Epoch 199/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.2231 - val_loss: 0.2156\n",
            "Epoch 200/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.2216 - val_loss: 0.2139\n",
            "Epoch 201/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.2198 - val_loss: 0.2122\n",
            "Epoch 202/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.2178 - val_loss: 0.2105\n",
            "Epoch 203/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.2161 - val_loss: 0.2089\n",
            "Epoch 204/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.2144 - val_loss: 0.2073\n",
            "Epoch 205/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.2128 - val_loss: 0.2056\n",
            "Epoch 206/1000\n",
            "120/120 [==============================] - 0s 106us/sample - loss: 0.2110 - val_loss: 0.2041\n",
            "Epoch 207/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.2094 - val_loss: 0.2025\n",
            "Epoch 208/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.2077 - val_loss: 0.2009\n",
            "Epoch 209/1000\n",
            "120/120 [==============================] - 0s 114us/sample - loss: 0.2063 - val_loss: 0.1993\n",
            "Epoch 210/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.2045 - val_loss: 0.1977\n",
            "Epoch 211/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.2030 - val_loss: 0.1962\n",
            "Epoch 212/1000\n",
            "120/120 [==============================] - 0s 121us/sample - loss: 0.2014 - val_loss: 0.1946\n",
            "Epoch 213/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.2005 - val_loss: 0.1932\n",
            "Epoch 214/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.1985 - val_loss: 0.1917\n",
            "Epoch 215/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1969 - val_loss: 0.1902\n",
            "Epoch 216/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.1953 - val_loss: 0.1888\n",
            "Epoch 217/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.1943 - val_loss: 0.1876\n",
            "Epoch 218/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.1926 - val_loss: 0.1861\n",
            "Epoch 219/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.1911 - val_loss: 0.1846\n",
            "Epoch 220/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1898 - val_loss: 0.1832\n",
            "Epoch 221/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.1883 - val_loss: 0.1817\n",
            "Epoch 222/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.1868 - val_loss: 0.1804\n",
            "Epoch 223/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1857 - val_loss: 0.1791\n",
            "Epoch 224/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.1842 - val_loss: 0.1777\n",
            "Epoch 225/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.1828 - val_loss: 0.1764\n",
            "Epoch 226/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.1815 - val_loss: 0.1752\n",
            "Epoch 227/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.1804 - val_loss: 0.1740\n",
            "Epoch 228/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.1789 - val_loss: 0.1727\n",
            "Epoch 229/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.1776 - val_loss: 0.1714\n",
            "Epoch 230/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.1767 - val_loss: 0.1701\n",
            "Epoch 231/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.1755 - val_loss: 0.1689\n",
            "Epoch 232/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1741 - val_loss: 0.1676\n",
            "Epoch 233/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.1727 - val_loss: 0.1665\n",
            "Epoch 234/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.1715 - val_loss: 0.1653\n",
            "Epoch 235/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.1704 - val_loss: 0.1642\n",
            "Epoch 236/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.1692 - val_loss: 0.1629\n",
            "Epoch 237/1000\n",
            "120/120 [==============================] - 0s 99us/sample - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 238/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.1668 - val_loss: 0.1607\n",
            "Epoch 239/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.1656 - val_loss: 0.1595\n",
            "Epoch 240/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.1645 - val_loss: 0.1584\n",
            "Epoch 241/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.1635 - val_loss: 0.1574\n",
            "Epoch 242/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.1624 - val_loss: 0.1563\n",
            "Epoch 243/1000\n",
            "120/120 [==============================] - 0s 138us/sample - loss: 0.1615 - val_loss: 0.1552\n",
            "Epoch 244/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.1604 - val_loss: 0.1541\n",
            "Epoch 245/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.1592 - val_loss: 0.1531\n",
            "Epoch 246/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.1586 - val_loss: 0.1521\n",
            "Epoch 247/1000\n",
            "120/120 [==============================] - 0s 124us/sample - loss: 0.1571 - val_loss: 0.1510\n",
            "Epoch 248/1000\n",
            "120/120 [==============================] - 0s 128us/sample - loss: 0.1563 - val_loss: 0.1501\n",
            "Epoch 249/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.1552 - val_loss: 0.1492\n",
            "Epoch 250/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.1541 - val_loss: 0.1482\n",
            "Epoch 251/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1531 - val_loss: 0.1472\n",
            "Epoch 252/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.1521 - val_loss: 0.1461\n",
            "Epoch 253/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.1514 - val_loss: 0.1452\n",
            "Epoch 254/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.1503 - val_loss: 0.1442\n",
            "Epoch 255/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.1493 - val_loss: 0.1433\n",
            "Epoch 256/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1483 - val_loss: 0.1424\n",
            "Epoch 257/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.1474 - val_loss: 0.1415\n",
            "Epoch 258/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.1465 - val_loss: 0.1406\n",
            "Epoch 259/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.1458 - val_loss: 0.1398\n",
            "Epoch 260/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1449 - val_loss: 0.1389\n",
            "Epoch 261/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.1439 - val_loss: 0.1379\n",
            "Epoch 262/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.1433 - val_loss: 0.1370\n",
            "Epoch 263/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.1423 - val_loss: 0.1362\n",
            "Epoch 264/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.1420 - val_loss: 0.1353\n",
            "Epoch 265/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.1406 - val_loss: 0.1345\n",
            "Epoch 266/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.1397 - val_loss: 0.1337\n",
            "Epoch 267/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.1390 - val_loss: 0.1329\n",
            "Epoch 268/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.1384 - val_loss: 0.1321\n",
            "Epoch 269/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.1373 - val_loss: 0.1313\n",
            "Epoch 270/1000\n",
            "120/120 [==============================] - 0s 114us/sample - loss: 0.1366 - val_loss: 0.1305\n",
            "Epoch 271/1000\n",
            "120/120 [==============================] - 0s 120us/sample - loss: 0.1358 - val_loss: 0.1297\n",
            "Epoch 272/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.1350 - val_loss: 0.1289\n",
            "Epoch 273/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.1344 - val_loss: 0.1282\n",
            "Epoch 274/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.1335 - val_loss: 0.1274\n",
            "Epoch 275/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.1328 - val_loss: 0.1267\n",
            "Epoch 276/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.1323 - val_loss: 0.1259\n",
            "Epoch 277/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.1313 - val_loss: 0.1252\n",
            "Epoch 278/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.1307 - val_loss: 0.1245\n",
            "Epoch 279/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.1298 - val_loss: 0.1238\n",
            "Epoch 280/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.1292 - val_loss: 0.1231\n",
            "Epoch 281/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.1285 - val_loss: 0.1225\n",
            "Epoch 282/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.1284 - val_loss: 0.1217\n",
            "Epoch 283/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.1271 - val_loss: 0.1211\n",
            "Epoch 284/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.1266 - val_loss: 0.1204\n",
            "Epoch 285/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.1262 - val_loss: 0.1198\n",
            "Epoch 286/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1253 - val_loss: 0.1190\n",
            "Epoch 287/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.1247 - val_loss: 0.1184\n",
            "Epoch 288/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.1239 - val_loss: 0.1177\n",
            "Epoch 289/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.1234 - val_loss: 0.1171\n",
            "Epoch 290/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.1227 - val_loss: 0.1165\n",
            "Epoch 291/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.1222 - val_loss: 0.1158\n",
            "Epoch 292/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.1215 - val_loss: 0.1152\n",
            "Epoch 293/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.1209 - val_loss: 0.1146\n",
            "Epoch 294/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.1207 - val_loss: 0.1140\n",
            "Epoch 295/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.1197 - val_loss: 0.1134\n",
            "Epoch 296/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.1193 - val_loss: 0.1128\n",
            "Epoch 297/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1194 - val_loss: 0.1122\n",
            "Epoch 298/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.1180 - val_loss: 0.1117\n",
            "Epoch 299/1000\n",
            "120/120 [==============================] - 0s 107us/sample - loss: 0.1174 - val_loss: 0.1111\n",
            "Epoch 300/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1169 - val_loss: 0.1106\n",
            "Epoch 301/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.1163 - val_loss: 0.1100\n",
            "Epoch 302/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.1159 - val_loss: 0.1094\n",
            "Epoch 303/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.1153 - val_loss: 0.1088\n",
            "Epoch 304/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.1148 - val_loss: 0.1083\n",
            "Epoch 305/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.1143 - val_loss: 0.1078\n",
            "Epoch 306/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.1138 - val_loss: 0.1072\n",
            "Epoch 307/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.1132 - val_loss: 0.1067\n",
            "Epoch 308/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1128 - val_loss: 0.1062\n",
            "Epoch 309/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.1122 - val_loss: 0.1057\n",
            "Epoch 310/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1118 - val_loss: 0.1052\n",
            "Epoch 311/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1112 - val_loss: 0.1046\n",
            "Epoch 312/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.1108 - val_loss: 0.1041\n",
            "Epoch 313/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.1107 - val_loss: 0.1036\n",
            "Epoch 314/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.1100 - val_loss: 0.1032\n",
            "Epoch 315/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.1093 - val_loss: 0.1027\n",
            "Epoch 316/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.1089 - val_loss: 0.1022\n",
            "Epoch 317/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.1083 - val_loss: 0.1017\n",
            "Epoch 318/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.1079 - val_loss: 0.1013\n",
            "Epoch 319/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.1075 - val_loss: 0.1009\n",
            "Epoch 320/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.1072 - val_loss: 0.1004\n",
            "Epoch 321/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.1066 - val_loss: 0.0999\n",
            "Epoch 322/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.1062 - val_loss: 0.0995\n",
            "Epoch 323/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.1057 - val_loss: 0.0990\n",
            "Epoch 324/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.1054 - val_loss: 0.0985\n",
            "Epoch 325/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.1050 - val_loss: 0.0980\n",
            "Epoch 326/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.1045 - val_loss: 0.0976\n",
            "Epoch 327/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.1040 - val_loss: 0.0972\n",
            "Epoch 328/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.1039 - val_loss: 0.0968\n",
            "Epoch 329/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.1033 - val_loss: 0.0964\n",
            "Epoch 330/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.1029 - val_loss: 0.0959\n",
            "Epoch 331/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.1024 - val_loss: 0.0955\n",
            "Epoch 332/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.1020 - val_loss: 0.0951\n",
            "Epoch 333/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.1018 - val_loss: 0.0946\n",
            "Epoch 334/1000\n",
            "120/120 [==============================] - 0s 130us/sample - loss: 0.1013 - val_loss: 0.0943\n",
            "Epoch 335/1000\n",
            "120/120 [==============================] - 0s 109us/sample - loss: 0.1013 - val_loss: 0.0940\n",
            "Epoch 336/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.1005 - val_loss: 0.0936\n",
            "Epoch 337/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.1001 - val_loss: 0.0931\n",
            "Epoch 338/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0998 - val_loss: 0.0927\n",
            "Epoch 339/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0995 - val_loss: 0.0923\n",
            "Epoch 340/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0990 - val_loss: 0.0919\n",
            "Epoch 341/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0993 - val_loss: 0.0916\n",
            "Epoch 342/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0983 - val_loss: 0.0912\n",
            "Epoch 343/1000\n",
            "120/120 [==============================] - 0s 139us/sample - loss: 0.0979 - val_loss: 0.0908\n",
            "Epoch 344/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0977 - val_loss: 0.0904\n",
            "Epoch 345/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0973 - val_loss: 0.0900\n",
            "Epoch 346/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.0971 - val_loss: 0.0897\n",
            "Epoch 347/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0966 - val_loss: 0.0893\n",
            "Epoch 348/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0963 - val_loss: 0.0889\n",
            "Epoch 349/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0966 - val_loss: 0.0886\n",
            "Epoch 350/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0957 - val_loss: 0.0883\n",
            "Epoch 351/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0954 - val_loss: 0.0879\n",
            "Epoch 352/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0949 - val_loss: 0.0875\n",
            "Epoch 353/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0946 - val_loss: 0.0872\n",
            "Epoch 354/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0943 - val_loss: 0.0869\n",
            "Epoch 355/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0940 - val_loss: 0.0866\n",
            "Epoch 356/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0937 - val_loss: 0.0863\n",
            "Epoch 357/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0933 - val_loss: 0.0860\n",
            "Epoch 358/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0931 - val_loss: 0.0857\n",
            "Epoch 359/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0928 - val_loss: 0.0853\n",
            "Epoch 360/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0925 - val_loss: 0.0850\n",
            "Epoch 361/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0924 - val_loss: 0.0846\n",
            "Epoch 362/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0919 - val_loss: 0.0843\n",
            "Epoch 363/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0919 - val_loss: 0.0840\n",
            "Epoch 364/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0915 - val_loss: 0.0836\n",
            "Epoch 365/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0910 - val_loss: 0.0834\n",
            "Epoch 366/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0907 - val_loss: 0.0831\n",
            "Epoch 367/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0905 - val_loss: 0.0829\n",
            "Epoch 368/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0903 - val_loss: 0.0825\n",
            "Epoch 369/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0903 - val_loss: 0.0824\n",
            "Epoch 370/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0897 - val_loss: 0.0821\n",
            "Epoch 371/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0894 - val_loss: 0.0816\n",
            "Epoch 372/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.0894 - val_loss: 0.0814\n",
            "Epoch 373/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0888 - val_loss: 0.0810\n",
            "Epoch 374/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0885 - val_loss: 0.0807\n",
            "Epoch 375/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0884 - val_loss: 0.0804\n",
            "Epoch 376/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0884 - val_loss: 0.0801\n",
            "Epoch 377/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0880 - val_loss: 0.0798\n",
            "Epoch 378/1000\n",
            "120/120 [==============================] - 0s 113us/sample - loss: 0.0876 - val_loss: 0.0796\n",
            "Epoch 379/1000\n",
            "120/120 [==============================] - 0s 136us/sample - loss: 0.0874 - val_loss: 0.0793\n",
            "Epoch 380/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0871 - val_loss: 0.0791\n",
            "Epoch 381/1000\n",
            "120/120 [==============================] - 0s 99us/sample - loss: 0.0870 - val_loss: 0.0790\n",
            "Epoch 382/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0866 - val_loss: 0.0786\n",
            "Epoch 383/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0866 - val_loss: 0.0784\n",
            "Epoch 384/1000\n",
            "120/120 [==============================] - 0s 140us/sample - loss: 0.0861 - val_loss: 0.0781\n",
            "Epoch 385/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0859 - val_loss: 0.0778\n",
            "Epoch 386/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0856 - val_loss: 0.0775\n",
            "Epoch 387/1000\n",
            "120/120 [==============================] - 0s 106us/sample - loss: 0.0859 - val_loss: 0.0772\n",
            "Epoch 388/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0856 - val_loss: 0.0770\n",
            "Epoch 389/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0854 - val_loss: 0.0769\n",
            "Epoch 390/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0848 - val_loss: 0.0765\n",
            "Epoch 391/1000\n",
            "120/120 [==============================] - 0s 103us/sample - loss: 0.0847 - val_loss: 0.0763\n",
            "Epoch 392/1000\n",
            "120/120 [==============================] - 0s 106us/sample - loss: 0.0849 - val_loss: 0.0759\n",
            "Epoch 393/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0841 - val_loss: 0.0757\n",
            "Epoch 394/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0839 - val_loss: 0.0755\n",
            "Epoch 395/1000\n",
            "120/120 [==============================] - 0s 177us/sample - loss: 0.0837 - val_loss: 0.0753\n",
            "Epoch 396/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0835 - val_loss: 0.0752\n",
            "Epoch 397/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0841 - val_loss: 0.0754\n",
            "Epoch 398/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0831 - val_loss: 0.0751\n",
            "Epoch 399/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0829 - val_loss: 0.0746\n",
            "Epoch 400/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0826 - val_loss: 0.0742\n",
            "Epoch 401/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0826 - val_loss: 0.0739\n",
            "Epoch 402/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0823 - val_loss: 0.0736\n",
            "Epoch 403/1000\n",
            "120/120 [==============================] - 0s 160us/sample - loss: 0.0822 - val_loss: 0.0735\n",
            "Epoch 404/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0818 - val_loss: 0.0734\n",
            "Epoch 405/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0817 - val_loss: 0.0732\n",
            "Epoch 406/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0814 - val_loss: 0.0730\n",
            "Epoch 407/1000\n",
            "120/120 [==============================] - 0s 103us/sample - loss: 0.0814 - val_loss: 0.0726\n",
            "Epoch 408/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0811 - val_loss: 0.0723\n",
            "Epoch 409/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0811 - val_loss: 0.0722\n",
            "Epoch 410/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0815 - val_loss: 0.0722\n",
            "Epoch 411/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0809 - val_loss: 0.0720\n",
            "Epoch 412/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0805 - val_loss: 0.0715\n",
            "Epoch 413/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0801 - val_loss: 0.0712\n",
            "Epoch 414/1000\n",
            "120/120 [==============================] - 0s 128us/sample - loss: 0.0808 - val_loss: 0.0710\n",
            "Epoch 415/1000\n",
            "120/120 [==============================] - 0s 112us/sample - loss: 0.0799 - val_loss: 0.0708\n",
            "Epoch 416/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0795 - val_loss: 0.0707\n",
            "Epoch 417/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0793 - val_loss: 0.0707\n",
            "Epoch 418/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0794 - val_loss: 0.0710\n",
            "Epoch 419/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0791 - val_loss: 0.0709\n",
            "Epoch 420/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0790 - val_loss: 0.0706\n",
            "Epoch 421/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0788 - val_loss: 0.0702\n",
            "Epoch 422/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0786 - val_loss: 0.0698\n",
            "Epoch 423/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0784 - val_loss: 0.0694\n",
            "Epoch 424/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0782 - val_loss: 0.0692\n",
            "Epoch 425/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0780 - val_loss: 0.0690\n",
            "Epoch 426/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0780 - val_loss: 0.0688\n",
            "Epoch 427/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0777 - val_loss: 0.0687\n",
            "Epoch 428/1000\n",
            "120/120 [==============================] - 0s 115us/sample - loss: 0.0775 - val_loss: 0.0686\n",
            "Epoch 429/1000\n",
            "120/120 [==============================] - 0s 104us/sample - loss: 0.0773 - val_loss: 0.0685\n",
            "Epoch 430/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0772 - val_loss: 0.0684\n",
            "Epoch 431/1000\n",
            "120/120 [==============================] - 0s 52us/sample - loss: 0.0770 - val_loss: 0.0682\n",
            "Epoch 432/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0769 - val_loss: 0.0681\n",
            "Epoch 433/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0770 - val_loss: 0.0676\n",
            "Epoch 434/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0766 - val_loss: 0.0675\n",
            "Epoch 435/1000\n",
            "120/120 [==============================] - 0s 114us/sample - loss: 0.0767 - val_loss: 0.0674\n",
            "Epoch 436/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0768 - val_loss: 0.0669\n",
            "Epoch 437/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0762 - val_loss: 0.0668\n",
            "Epoch 438/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0762 - val_loss: 0.0668\n",
            "Epoch 439/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0760 - val_loss: 0.0664\n",
            "Epoch 440/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0757 - val_loss: 0.0663\n",
            "Epoch 441/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0755 - val_loss: 0.0661\n",
            "Epoch 442/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0755 - val_loss: 0.0660\n",
            "Epoch 443/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0752 - val_loss: 0.0660\n",
            "Epoch 444/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0751 - val_loss: 0.0658\n",
            "Epoch 445/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0753 - val_loss: 0.0660\n",
            "Epoch 446/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0748 - val_loss: 0.0657\n",
            "Epoch 447/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0748 - val_loss: 0.0654\n",
            "Epoch 448/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0746 - val_loss: 0.0651\n",
            "Epoch 449/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0746 - val_loss: 0.0651\n",
            "Epoch 450/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0743 - val_loss: 0.0649\n",
            "Epoch 451/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0743 - val_loss: 0.0645\n",
            "Epoch 452/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0740 - val_loss: 0.0644\n",
            "Epoch 453/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0742 - val_loss: 0.0641\n",
            "Epoch 454/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.0742 - val_loss: 0.0642\n",
            "Epoch 455/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0736 - val_loss: 0.0641\n",
            "Epoch 456/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0737 - val_loss: 0.0639\n",
            "Epoch 457/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0737 - val_loss: 0.0640\n",
            "Epoch 458/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0733 - val_loss: 0.0639\n",
            "Epoch 459/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0732 - val_loss: 0.0635\n",
            "Epoch 460/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0729 - val_loss: 0.0633\n",
            "Epoch 461/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0728 - val_loss: 0.0631\n",
            "Epoch 462/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0727 - val_loss: 0.0630\n",
            "Epoch 463/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0728 - val_loss: 0.0629\n",
            "Epoch 464/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0725 - val_loss: 0.0626\n",
            "Epoch 465/1000\n",
            "120/120 [==============================] - 0s 135us/sample - loss: 0.0724 - val_loss: 0.0624\n",
            "Epoch 466/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0723 - val_loss: 0.0622\n",
            "Epoch 467/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0722 - val_loss: 0.0621\n",
            "Epoch 468/1000\n",
            "120/120 [==============================] - 0s 118us/sample - loss: 0.0723 - val_loss: 0.0624\n",
            "Epoch 469/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0718 - val_loss: 0.0624\n",
            "Epoch 470/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0723 - val_loss: 0.0625\n",
            "Epoch 471/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0718 - val_loss: 0.0620\n",
            "Epoch 472/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0715 - val_loss: 0.0616\n",
            "Epoch 473/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0714 - val_loss: 0.0614\n",
            "Epoch 474/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0713 - val_loss: 0.0612\n",
            "Epoch 475/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0712 - val_loss: 0.0610\n",
            "Epoch 476/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0712 - val_loss: 0.0609\n",
            "Epoch 477/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0709 - val_loss: 0.0609\n",
            "Epoch 478/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0711 - val_loss: 0.0611\n",
            "Epoch 479/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0710 - val_loss: 0.0609\n",
            "Epoch 480/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0706 - val_loss: 0.0609\n",
            "Epoch 481/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0715 - val_loss: 0.0612\n",
            "Epoch 482/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0710 - val_loss: 0.0605\n",
            "Epoch 483/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0703 - val_loss: 0.0603\n",
            "Epoch 484/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0702 - val_loss: 0.0600\n",
            "Epoch 485/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0701 - val_loss: 0.0598\n",
            "Epoch 486/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0700 - val_loss: 0.0596\n",
            "Epoch 487/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0700 - val_loss: 0.0595\n",
            "Epoch 488/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0697 - val_loss: 0.0595\n",
            "Epoch 489/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0698 - val_loss: 0.0597\n",
            "Epoch 490/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0697 - val_loss: 0.0598\n",
            "Epoch 491/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0695 - val_loss: 0.0595\n",
            "Epoch 492/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0696 - val_loss: 0.0591\n",
            "Epoch 493/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0695 - val_loss: 0.0588\n",
            "Epoch 494/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0694 - val_loss: 0.0589\n",
            "Epoch 495/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0696 - val_loss: 0.0585\n",
            "Epoch 496/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0694 - val_loss: 0.0587\n",
            "Epoch 497/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0689 - val_loss: 0.0586\n",
            "Epoch 498/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0688 - val_loss: 0.0585\n",
            "Epoch 499/1000\n",
            "120/120 [==============================] - 0s 109us/sample - loss: 0.0689 - val_loss: 0.0581\n",
            "Epoch 500/1000\n",
            "120/120 [==============================] - 0s 132us/sample - loss: 0.0686 - val_loss: 0.0579\n",
            "Epoch 501/1000\n",
            "120/120 [==============================] - 0s 99us/sample - loss: 0.0686 - val_loss: 0.0578\n",
            "Epoch 502/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0686 - val_loss: 0.0579\n",
            "Epoch 503/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0685 - val_loss: 0.0581\n",
            "Epoch 504/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0682 - val_loss: 0.0579\n",
            "Epoch 505/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0682 - val_loss: 0.0578\n",
            "Epoch 506/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0683 - val_loss: 0.0573\n",
            "Epoch 507/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0680 - val_loss: 0.0572\n",
            "Epoch 508/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0678 - val_loss: 0.0570\n",
            "Epoch 509/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0678 - val_loss: 0.0570\n",
            "Epoch 510/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0681 - val_loss: 0.0570\n",
            "Epoch 511/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0676 - val_loss: 0.0567\n",
            "Epoch 512/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0675 - val_loss: 0.0566\n",
            "Epoch 513/1000\n",
            "120/120 [==============================] - 0s 116us/sample - loss: 0.0674 - val_loss: 0.0565\n",
            "Epoch 514/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0674 - val_loss: 0.0565\n",
            "Epoch 515/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0672 - val_loss: 0.0564\n",
            "Epoch 516/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0673 - val_loss: 0.0561\n",
            "Epoch 517/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0671 - val_loss: 0.0562\n",
            "Epoch 518/1000\n",
            "120/120 [==============================] - 0s 118us/sample - loss: 0.0675 - val_loss: 0.0559\n",
            "Epoch 519/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.0670 - val_loss: 0.0561\n",
            "Epoch 520/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0669 - val_loss: 0.0563\n",
            "Epoch 521/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0669 - val_loss: 0.0564\n",
            "Epoch 522/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0668 - val_loss: 0.0559\n",
            "Epoch 523/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0666 - val_loss: 0.0558\n",
            "Epoch 524/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0665 - val_loss: 0.0556\n",
            "Epoch 525/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0664 - val_loss: 0.0553\n",
            "Epoch 526/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0667 - val_loss: 0.0550\n",
            "Epoch 527/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0664 - val_loss: 0.0549\n",
            "Epoch 528/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0662 - val_loss: 0.0550\n",
            "Epoch 529/1000\n",
            "120/120 [==============================] - 0s 110us/sample - loss: 0.0660 - val_loss: 0.0551\n",
            "Epoch 530/1000\n",
            "120/120 [==============================] - 0s 104us/sample - loss: 0.0660 - val_loss: 0.0552\n",
            "Epoch 531/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0659 - val_loss: 0.0552\n",
            "Epoch 532/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0659 - val_loss: 0.0551\n",
            "Epoch 533/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.0658 - val_loss: 0.0549\n",
            "Epoch 534/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0659 - val_loss: 0.0546\n",
            "Epoch 535/1000\n",
            "120/120 [==============================] - 0s 121us/sample - loss: 0.0658 - val_loss: 0.0544\n",
            "Epoch 536/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0655 - val_loss: 0.0545\n",
            "Epoch 537/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0655 - val_loss: 0.0546\n",
            "Epoch 538/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0655 - val_loss: 0.0543\n",
            "Epoch 539/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0657 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0653 - val_loss: 0.0541\n",
            "Epoch 541/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0656 - val_loss: 0.0543\n",
            "Epoch 542/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0651 - val_loss: 0.0541\n",
            "Epoch 543/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0654 - val_loss: 0.0540\n",
            "Epoch 544/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0649 - val_loss: 0.0535\n",
            "Epoch 545/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0650 - val_loss: 0.0531\n",
            "Epoch 546/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0650 - val_loss: 0.0531\n",
            "Epoch 547/1000\n",
            "120/120 [==============================] - 0s 59us/sample - loss: 0.0650 - val_loss: 0.0530\n",
            "Epoch 548/1000\n",
            "120/120 [==============================] - 0s 59us/sample - loss: 0.0648 - val_loss: 0.0530\n",
            "Epoch 549/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0648 - val_loss: 0.0530\n",
            "Epoch 550/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0647 - val_loss: 0.0530\n",
            "Epoch 551/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0646 - val_loss: 0.0528\n",
            "Epoch 552/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0646 - val_loss: 0.0528\n",
            "Epoch 553/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0644 - val_loss: 0.0528\n",
            "Epoch 554/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0648 - val_loss: 0.0529\n",
            "Epoch 555/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0642 - val_loss: 0.0526\n",
            "Epoch 556/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0642 - val_loss: 0.0524\n",
            "Epoch 557/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0642 - val_loss: 0.0521\n",
            "Epoch 558/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0645 - val_loss: 0.0519\n",
            "Epoch 559/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0641 - val_loss: 0.0520\n",
            "Epoch 560/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0641 - val_loss: 0.0522\n",
            "Epoch 561/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0638 - val_loss: 0.0523\n",
            "Epoch 562/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0638 - val_loss: 0.0523\n",
            "Epoch 563/1000\n",
            "120/120 [==============================] - 0s 111us/sample - loss: 0.0637 - val_loss: 0.0521\n",
            "Epoch 564/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0641 - val_loss: 0.0518\n",
            "Epoch 565/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0637 - val_loss: 0.0517\n",
            "Epoch 566/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0636 - val_loss: 0.0520\n",
            "Epoch 567/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0634 - val_loss: 0.0520\n",
            "Epoch 568/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0634 - val_loss: 0.0519\n",
            "Epoch 569/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0634 - val_loss: 0.0517\n",
            "Epoch 570/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0633 - val_loss: 0.0517\n",
            "Epoch 571/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0634 - val_loss: 0.0513\n",
            "Epoch 572/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0632 - val_loss: 0.0513\n",
            "Epoch 573/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0636 - val_loss: 0.0509\n",
            "Epoch 574/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0630 - val_loss: 0.0510\n",
            "Epoch 575/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0630 - val_loss: 0.0509\n",
            "Epoch 576/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0635 - val_loss: 0.0513\n",
            "Epoch 577/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0636 - val_loss: 0.0515\n",
            "Epoch 578/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0629 - val_loss: 0.0512\n",
            "Epoch 579/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0628 - val_loss: 0.0507\n",
            "Epoch 580/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0627 - val_loss: 0.0502\n",
            "Epoch 581/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0628 - val_loss: 0.0499\n",
            "Epoch 582/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0628 - val_loss: 0.0499\n",
            "Epoch 583/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0627 - val_loss: 0.0499\n",
            "Epoch 584/1000\n",
            "120/120 [==============================] - 0s 126us/sample - loss: 0.0629 - val_loss: 0.0501\n",
            "Epoch 585/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0628 - val_loss: 0.0504\n",
            "Epoch 586/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0624 - val_loss: 0.0502\n",
            "Epoch 587/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0623 - val_loss: 0.0502\n",
            "Epoch 588/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0622 - val_loss: 0.0501\n",
            "Epoch 589/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0622 - val_loss: 0.0501\n",
            "Epoch 590/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0623 - val_loss: 0.0502\n",
            "Epoch 591/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0621 - val_loss: 0.0499\n",
            "Epoch 592/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0623 - val_loss: 0.0495\n",
            "Epoch 593/1000\n",
            "120/120 [==============================] - 0s 114us/sample - loss: 0.0622 - val_loss: 0.0493\n",
            "Epoch 594/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0620 - val_loss: 0.0495\n",
            "Epoch 595/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0621 - val_loss: 0.0494\n",
            "Epoch 596/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0618 - val_loss: 0.0496\n",
            "Epoch 597/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0618 - val_loss: 0.0495\n",
            "Epoch 598/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0617 - val_loss: 0.0495\n",
            "Epoch 599/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0620 - val_loss: 0.0498\n",
            "Epoch 600/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0617 - val_loss: 0.0497\n",
            "Epoch 601/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0616 - val_loss: 0.0493\n",
            "Epoch 602/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0617 - val_loss: 0.0491\n",
            "Epoch 603/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0614 - val_loss: 0.0486\n",
            "Epoch 604/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0617 - val_loss: 0.0483\n",
            "Epoch 605/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0615 - val_loss: 0.0483\n",
            "Epoch 606/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0620 - val_loss: 0.0485\n",
            "Epoch 607/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0612 - val_loss: 0.0484\n",
            "Epoch 608/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0615 - val_loss: 0.0485\n",
            "Epoch 609/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0612 - val_loss: 0.0483\n",
            "Epoch 610/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0611 - val_loss: 0.0482\n",
            "Epoch 611/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0610 - val_loss: 0.0482\n",
            "Epoch 612/1000\n",
            "120/120 [==============================] - 0s 99us/sample - loss: 0.0612 - val_loss: 0.0481\n",
            "Epoch 613/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0612 - val_loss: 0.0484\n",
            "Epoch 614/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0609 - val_loss: 0.0484\n",
            "Epoch 615/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0609 - val_loss: 0.0483\n",
            "Epoch 616/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0608 - val_loss: 0.0482\n",
            "Epoch 617/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0609 - val_loss: 0.0480\n",
            "Epoch 618/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0608 - val_loss: 0.0479\n",
            "Epoch 619/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0607 - val_loss: 0.0479\n",
            "Epoch 620/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0609 - val_loss: 0.0477\n",
            "Epoch 621/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0606 - val_loss: 0.0479\n",
            "Epoch 622/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0609 - val_loss: 0.0477\n",
            "Epoch 623/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0608 - val_loss: 0.0481\n",
            "Epoch 624/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0606 - val_loss: 0.0479\n",
            "Epoch 625/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0604 - val_loss: 0.0478\n",
            "Epoch 626/1000\n",
            "120/120 [==============================] - 0s 117us/sample - loss: 0.0604 - val_loss: 0.0477\n",
            "Epoch 627/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0603 - val_loss: 0.0475\n",
            "Epoch 628/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0603 - val_loss: 0.0472\n",
            "Epoch 629/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0602 - val_loss: 0.0471\n",
            "Epoch 630/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0602 - val_loss: 0.0470\n",
            "Epoch 631/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0602 - val_loss: 0.0469\n",
            "Epoch 632/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0601 - val_loss: 0.0468\n",
            "Epoch 633/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0601 - val_loss: 0.0467\n",
            "Epoch 634/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0600 - val_loss: 0.0467\n",
            "Epoch 635/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0602 - val_loss: 0.0466\n",
            "Epoch 636/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0600 - val_loss: 0.0468\n",
            "Epoch 637/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0599 - val_loss: 0.0468\n",
            "Epoch 638/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0599 - val_loss: 0.0471\n",
            "Epoch 639/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0598 - val_loss: 0.0470\n",
            "Epoch 640/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0600 - val_loss: 0.0467\n",
            "Epoch 641/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0597 - val_loss: 0.0465\n",
            "Epoch 642/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0597 - val_loss: 0.0464\n",
            "Epoch 643/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0597 - val_loss: 0.0464\n",
            "Epoch 644/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0597 - val_loss: 0.0464\n",
            "Epoch 645/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0598 - val_loss: 0.0460\n",
            "Epoch 646/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0596 - val_loss: 0.0460\n",
            "Epoch 647/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0595 - val_loss: 0.0459\n",
            "Epoch 648/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0598 - val_loss: 0.0463\n",
            "Epoch 649/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0596 - val_loss: 0.0464\n",
            "Epoch 650/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0596 - val_loss: 0.0460\n",
            "Epoch 651/1000\n",
            "120/120 [==============================] - 0s 122us/sample - loss: 0.0594 - val_loss: 0.0457\n",
            "Epoch 652/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0595 - val_loss: 0.0455\n",
            "Epoch 653/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0594 - val_loss: 0.0457\n",
            "Epoch 654/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0592 - val_loss: 0.0457\n",
            "Epoch 655/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0594 - val_loss: 0.0455\n",
            "Epoch 656/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0594 - val_loss: 0.0459\n",
            "Epoch 657/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0598 - val_loss: 0.0455\n",
            "Epoch 658/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0592 - val_loss: 0.0458\n",
            "Epoch 659/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0595 - val_loss: 0.0460\n",
            "Epoch 660/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0591 - val_loss: 0.0456\n",
            "Epoch 661/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0589 - val_loss: 0.0453\n",
            "Epoch 662/1000\n",
            "120/120 [==============================] - 0s 64us/sample - loss: 0.0589 - val_loss: 0.0451\n",
            "Epoch 663/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0591 - val_loss: 0.0451\n",
            "Epoch 664/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0588 - val_loss: 0.0449\n",
            "Epoch 665/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0593 - val_loss: 0.0446\n",
            "Epoch 666/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0589 - val_loss: 0.0447\n",
            "Epoch 667/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0592 - val_loss: 0.0450\n",
            "Epoch 668/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0592 - val_loss: 0.0447\n",
            "Epoch 669/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0587 - val_loss: 0.0449\n",
            "Epoch 670/1000\n",
            "120/120 [==============================] - 0s 132us/sample - loss: 0.0587 - val_loss: 0.0448\n",
            "Epoch 671/1000\n",
            "120/120 [==============================] - 0s 138us/sample - loss: 0.0591 - val_loss: 0.0452\n",
            "Epoch 672/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0587 - val_loss: 0.0449\n",
            "Epoch 673/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0586 - val_loss: 0.0448\n",
            "Epoch 674/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0587 - val_loss: 0.0448\n",
            "Epoch 675/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0585 - val_loss: 0.0444\n",
            "Epoch 676/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0585 - val_loss: 0.0443\n",
            "Epoch 677/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0584 - val_loss: 0.0440\n",
            "Epoch 678/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0584 - val_loss: 0.0440\n",
            "Epoch 679/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0584 - val_loss: 0.0440\n",
            "Epoch 680/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0583 - val_loss: 0.0440\n",
            "Epoch 681/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0583 - val_loss: 0.0441\n",
            "Epoch 682/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0582 - val_loss: 0.0442\n",
            "Epoch 683/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0583 - val_loss: 0.0445\n",
            "Epoch 684/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0582 - val_loss: 0.0446\n",
            "Epoch 685/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0591 - val_loss: 0.0449\n",
            "Epoch 686/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0582 - val_loss: 0.0442\n",
            "Epoch 687/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0580 - val_loss: 0.0437\n",
            "Epoch 688/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0589 - val_loss: 0.0432\n",
            "Epoch 689/1000\n",
            "120/120 [==============================] - 0s 100us/sample - loss: 0.0581 - val_loss: 0.0432\n",
            "Epoch 690/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.0581 - val_loss: 0.0433\n",
            "Epoch 691/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0580 - val_loss: 0.0435\n",
            "Epoch 692/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0583 - val_loss: 0.0439\n",
            "Epoch 693/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0583 - val_loss: 0.0436\n",
            "Epoch 694/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0579 - val_loss: 0.0438\n",
            "Epoch 695/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0581 - val_loss: 0.0440\n",
            "Epoch 696/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0580 - val_loss: 0.0439\n",
            "Epoch 697/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0579 - val_loss: 0.0433\n",
            "Epoch 698/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0579 - val_loss: 0.0433\n",
            "Epoch 699/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0576 - val_loss: 0.0430\n",
            "Epoch 700/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0580 - val_loss: 0.0427\n",
            "Epoch 701/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0585 - val_loss: 0.0425\n",
            "Epoch 702/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0577 - val_loss: 0.0428\n",
            "Epoch 703/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0575 - val_loss: 0.0431\n",
            "Epoch 704/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0577 - val_loss: 0.0433\n",
            "Epoch 705/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0575 - val_loss: 0.0438\n",
            "Epoch 706/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0579 - val_loss: 0.0443\n",
            "Epoch 707/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0583 - val_loss: 0.0436\n",
            "Epoch 708/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0577 - val_loss: 0.0437\n",
            "Epoch 709/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0576 - val_loss: 0.0434\n",
            "Epoch 710/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0574 - val_loss: 0.0427\n",
            "Epoch 711/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0573 - val_loss: 0.0423\n",
            "Epoch 712/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0579 - val_loss: 0.0420\n",
            "Epoch 713/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0574 - val_loss: 0.0420\n",
            "Epoch 714/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0575 - val_loss: 0.0420\n",
            "Epoch 715/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0573 - val_loss: 0.0424\n",
            "Epoch 716/1000\n",
            "120/120 [==============================] - 0s 116us/sample - loss: 0.0577 - val_loss: 0.0425\n",
            "Epoch 717/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0573 - val_loss: 0.0432\n",
            "Epoch 718/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0577 - val_loss: 0.0438\n",
            "Epoch 719/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0577 - val_loss: 0.0437\n",
            "Epoch 720/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0572 - val_loss: 0.0429\n",
            "Epoch 721/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0570 - val_loss: 0.0423\n",
            "Epoch 722/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0572 - val_loss: 0.0417\n",
            "Epoch 723/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.0571 - val_loss: 0.0415\n",
            "Epoch 724/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0572 - val_loss: 0.0414\n",
            "Epoch 725/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0572 - val_loss: 0.0414\n",
            "Epoch 726/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0570 - val_loss: 0.0415\n",
            "Epoch 727/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0571 - val_loss: 0.0420\n",
            "Epoch 728/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0569 - val_loss: 0.0424\n",
            "Epoch 729/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0569 - val_loss: 0.0426\n",
            "Epoch 730/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0570 - val_loss: 0.0427\n",
            "Epoch 731/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0570 - val_loss: 0.0422\n",
            "Epoch 732/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0581 - val_loss: 0.0415\n",
            "Epoch 733/1000\n",
            "120/120 [==============================] - 0s 99us/sample - loss: 0.0568 - val_loss: 0.0417\n",
            "Epoch 734/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0568 - val_loss: 0.0416\n",
            "Epoch 735/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0569 - val_loss: 0.0419\n",
            "Epoch 736/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0567 - val_loss: 0.0417\n",
            "Epoch 737/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0566 - val_loss: 0.0416\n",
            "Epoch 738/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0566 - val_loss: 0.0417\n",
            "Epoch 739/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0570 - val_loss: 0.0419\n",
            "Epoch 740/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0566 - val_loss: 0.0415\n",
            "Epoch 741/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0565 - val_loss: 0.0413\n",
            "Epoch 742/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0570 - val_loss: 0.0414\n",
            "Epoch 743/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0566 - val_loss: 0.0412\n",
            "Epoch 744/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0566 - val_loss: 0.0408\n",
            "Epoch 745/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0565 - val_loss: 0.0407\n",
            "Epoch 746/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0568 - val_loss: 0.0408\n",
            "Epoch 747/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0564 - val_loss: 0.0407\n",
            "Epoch 748/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0564 - val_loss: 0.0408\n",
            "Epoch 749/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0564 - val_loss: 0.0409\n",
            "Epoch 750/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0563 - val_loss: 0.0409\n",
            "Epoch 751/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0566 - val_loss: 0.0412\n",
            "Epoch 752/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0563 - val_loss: 0.0411\n",
            "Epoch 753/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0563 - val_loss: 0.0410\n",
            "Epoch 754/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0566 - val_loss: 0.0405\n",
            "Epoch 755/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0562 - val_loss: 0.0405\n",
            "Epoch 756/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0562 - val_loss: 0.0406\n",
            "Epoch 757/1000\n",
            "120/120 [==============================] - 0s 171us/sample - loss: 0.0566 - val_loss: 0.0403\n",
            "Epoch 758/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0561 - val_loss: 0.0405\n",
            "Epoch 759/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0561 - val_loss: 0.0407\n",
            "Epoch 760/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0565 - val_loss: 0.0412\n",
            "Epoch 761/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0565 - val_loss: 0.0408\n",
            "Epoch 762/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0561 - val_loss: 0.0409\n",
            "Epoch 763/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.0560 - val_loss: 0.0407\n",
            "Epoch 764/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0562 - val_loss: 0.0407\n",
            "Epoch 765/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0561 - val_loss: 0.0406\n",
            "Epoch 766/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0559 - val_loss: 0.0402\n",
            "Epoch 767/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0567 - val_loss: 0.0397\n",
            "Epoch 768/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0561 - val_loss: 0.0398\n",
            "Epoch 769/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0559 - val_loss: 0.0398\n",
            "Epoch 770/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0559 - val_loss: 0.0399\n",
            "Epoch 771/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0558 - val_loss: 0.0401\n",
            "Epoch 772/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0558 - val_loss: 0.0403\n",
            "Epoch 773/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0558 - val_loss: 0.0407\n",
            "Epoch 774/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0561 - val_loss: 0.0410\n",
            "Epoch 775/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0560 - val_loss: 0.0405\n",
            "Epoch 776/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0558 - val_loss: 0.0401\n",
            "Epoch 777/1000\n",
            "120/120 [==============================] - 0s 65us/sample - loss: 0.0557 - val_loss: 0.0399\n",
            "Epoch 778/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0558 - val_loss: 0.0396\n",
            "Epoch 779/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0557 - val_loss: 0.0397\n",
            "Epoch 780/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0560 - val_loss: 0.0395\n",
            "Epoch 781/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0558 - val_loss: 0.0395\n",
            "Epoch 782/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0564 - val_loss: 0.0401\n",
            "Epoch 783/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0556 - val_loss: 0.0400\n",
            "Epoch 784/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0556 - val_loss: 0.0400\n",
            "Epoch 785/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0557 - val_loss: 0.0397\n",
            "Epoch 786/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0558 - val_loss: 0.0398\n",
            "Epoch 787/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.0555 - val_loss: 0.0396\n",
            "Epoch 788/1000\n",
            "120/120 [==============================] - 0s 65us/sample - loss: 0.0570 - val_loss: 0.0390\n",
            "Epoch 789/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0558 - val_loss: 0.0389\n",
            "Epoch 790/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0561 - val_loss: 0.0395\n",
            "Epoch 791/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0554 - val_loss: 0.0397\n",
            "Epoch 792/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0554 - val_loss: 0.0397\n",
            "Epoch 793/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0554 - val_loss: 0.0397\n",
            "Epoch 794/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0554 - val_loss: 0.0396\n",
            "Epoch 795/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0559 - val_loss: 0.0397\n",
            "Epoch 796/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0554 - val_loss: 0.0394\n",
            "Epoch 797/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0553 - val_loss: 0.0390\n",
            "Epoch 798/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0556 - val_loss: 0.0384\n",
            "Epoch 799/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0554 - val_loss: 0.0384\n",
            "Epoch 800/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0554 - val_loss: 0.0384\n",
            "Epoch 801/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0553 - val_loss: 0.0385\n",
            "Epoch 802/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0553 - val_loss: 0.0386\n",
            "Epoch 803/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0554 - val_loss: 0.0391\n",
            "Epoch 804/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0551 - val_loss: 0.0393\n",
            "Epoch 805/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0555 - val_loss: 0.0397\n",
            "Epoch 806/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0552 - val_loss: 0.0393\n",
            "Epoch 807/1000\n",
            "120/120 [==============================] - 0s 66us/sample - loss: 0.0556 - val_loss: 0.0387\n",
            "Epoch 808/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0553 - val_loss: 0.0388\n",
            "Epoch 809/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0552 - val_loss: 0.0385\n",
            "Epoch 810/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0551 - val_loss: 0.0384\n",
            "Epoch 811/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0550 - val_loss: 0.0384\n",
            "Epoch 812/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0552 - val_loss: 0.0383\n",
            "Epoch 813/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0550 - val_loss: 0.0386\n",
            "Epoch 814/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0550 - val_loss: 0.0388\n",
            "Epoch 815/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0551 - val_loss: 0.0387\n",
            "Epoch 816/1000\n",
            "120/120 [==============================] - 0s 66us/sample - loss: 0.0549 - val_loss: 0.0387\n",
            "Epoch 817/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0549 - val_loss: 0.0388\n",
            "Epoch 818/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0551 - val_loss: 0.0389\n",
            "Epoch 819/1000\n",
            "120/120 [==============================] - 0s 64us/sample - loss: 0.0550 - val_loss: 0.0388\n",
            "Epoch 820/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0556 - val_loss: 0.0381\n",
            "Epoch 821/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0555 - val_loss: 0.0378\n",
            "Epoch 822/1000\n",
            "120/120 [==============================] - 0s 63us/sample - loss: 0.0559 - val_loss: 0.0383\n",
            "Epoch 823/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0549 - val_loss: 0.0381\n",
            "Epoch 824/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0550 - val_loss: 0.0383\n",
            "Epoch 825/1000\n",
            "120/120 [==============================] - 0s 68us/sample - loss: 0.0548 - val_loss: 0.0381\n",
            "Epoch 826/1000\n",
            "120/120 [==============================] - 0s 64us/sample - loss: 0.0550 - val_loss: 0.0379\n",
            "Epoch 827/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0547 - val_loss: 0.0380\n",
            "Epoch 828/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0554 - val_loss: 0.0384\n",
            "Epoch 829/1000\n",
            "120/120 [==============================] - 0s 69us/sample - loss: 0.0552 - val_loss: 0.0379\n",
            "Epoch 830/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0547 - val_loss: 0.0379\n",
            "Epoch 831/1000\n",
            "120/120 [==============================] - 0s 135us/sample - loss: 0.0547 - val_loss: 0.0379\n",
            "Epoch 832/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0555 - val_loss: 0.0383\n",
            "Epoch 833/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0549 - val_loss: 0.0383\n",
            "Epoch 834/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0553 - val_loss: 0.0375\n",
            "Epoch 835/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0547 - val_loss: 0.0374\n",
            "Epoch 836/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0547 - val_loss: 0.0375\n",
            "Epoch 837/1000\n",
            "120/120 [==============================] - 0s 93us/sample - loss: 0.0550 - val_loss: 0.0377\n",
            "Epoch 838/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0557 - val_loss: 0.0379\n",
            "Epoch 839/1000\n",
            "120/120 [==============================] - 0s 126us/sample - loss: 0.0547 - val_loss: 0.0377\n",
            "Epoch 840/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0544 - val_loss: 0.0373\n",
            "Epoch 841/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0547 - val_loss: 0.0371\n",
            "Epoch 842/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0551 - val_loss: 0.0368\n",
            "Epoch 843/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0555 - val_loss: 0.0367\n",
            "Epoch 844/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0550 - val_loss: 0.0368\n",
            "Epoch 845/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0545 - val_loss: 0.0373\n",
            "Epoch 846/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0545 - val_loss: 0.0378\n",
            "Epoch 847/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0543 - val_loss: 0.0385\n",
            "Epoch 848/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0545 - val_loss: 0.0390\n",
            "Epoch 849/1000\n",
            "120/120 [==============================] - 0s 130us/sample - loss: 0.0550 - val_loss: 0.0396\n",
            "Epoch 850/1000\n",
            "120/120 [==============================] - 0s 106us/sample - loss: 0.0549 - val_loss: 0.0391\n",
            "Epoch 851/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0554 - val_loss: 0.0380\n",
            "Epoch 852/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0546 - val_loss: 0.0373\n",
            "Epoch 853/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0545 - val_loss: 0.0373\n",
            "Epoch 854/1000\n",
            "120/120 [==============================] - 0s 103us/sample - loss: 0.0543 - val_loss: 0.0370\n",
            "Epoch 855/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0543 - val_loss: 0.0367\n",
            "Epoch 856/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0549 - val_loss: 0.0365\n",
            "Epoch 857/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0544 - val_loss: 0.0366\n",
            "Epoch 858/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0545 - val_loss: 0.0370\n",
            "Epoch 859/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.0542 - val_loss: 0.0371\n",
            "Epoch 860/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0542 - val_loss: 0.0372\n",
            "Epoch 861/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0544 - val_loss: 0.0376\n",
            "Epoch 862/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0542 - val_loss: 0.0376\n",
            "Epoch 863/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0543 - val_loss: 0.0373\n",
            "Epoch 864/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0547 - val_loss: 0.0374\n",
            "Epoch 865/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0541 - val_loss: 0.0370\n",
            "Epoch 866/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0541 - val_loss: 0.0366\n",
            "Epoch 867/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0541 - val_loss: 0.0363\n",
            "Epoch 868/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0542 - val_loss: 0.0363\n",
            "Epoch 869/1000\n",
            "120/120 [==============================] - 0s 115us/sample - loss: 0.0547 - val_loss: 0.0360\n",
            "Epoch 870/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0544 - val_loss: 0.0362\n",
            "Epoch 871/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0545 - val_loss: 0.0366\n",
            "Epoch 872/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0540 - val_loss: 0.0366\n",
            "Epoch 873/1000\n",
            "120/120 [==============================] - 0s 96us/sample - loss: 0.0541 - val_loss: 0.0365\n",
            "Epoch 874/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0542 - val_loss: 0.0367\n",
            "Epoch 875/1000\n",
            "120/120 [==============================] - 0s 108us/sample - loss: 0.0540 - val_loss: 0.0368\n",
            "Epoch 876/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.0540 - val_loss: 0.0365\n",
            "Epoch 877/1000\n",
            "120/120 [==============================] - 0s 101us/sample - loss: 0.0540 - val_loss: 0.0363\n",
            "Epoch 878/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0540 - val_loss: 0.0364\n",
            "Epoch 879/1000\n",
            "120/120 [==============================] - 0s 102us/sample - loss: 0.0541 - val_loss: 0.0362\n",
            "Epoch 880/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0541 - val_loss: 0.0365\n",
            "Epoch 881/1000\n",
            "120/120 [==============================] - 0s 137us/sample - loss: 0.0539 - val_loss: 0.0364\n",
            "Epoch 882/1000\n",
            "120/120 [==============================] - 0s 117us/sample - loss: 0.0545 - val_loss: 0.0362\n",
            "Epoch 883/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0539 - val_loss: 0.0363\n",
            "Epoch 884/1000\n",
            "120/120 [==============================] - 0s 112us/sample - loss: 0.0539 - val_loss: 0.0364\n",
            "Epoch 885/1000\n",
            "120/120 [==============================] - 0s 125us/sample - loss: 0.0538 - val_loss: 0.0367\n",
            "Epoch 886/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.0540 - val_loss: 0.0370\n",
            "Epoch 887/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0540 - val_loss: 0.0370\n",
            "Epoch 888/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0548 - val_loss: 0.0371\n",
            "Epoch 889/1000\n",
            "120/120 [==============================] - 0s 98us/sample - loss: 0.0538 - val_loss: 0.0363\n",
            "Epoch 890/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0538 - val_loss: 0.0356\n",
            "Epoch 891/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0540 - val_loss: 0.0353\n",
            "Epoch 892/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0540 - val_loss: 0.0353\n",
            "Epoch 893/1000\n",
            "120/120 [==============================] - 0s 107us/sample - loss: 0.0541 - val_loss: 0.0353\n",
            "Epoch 894/1000\n",
            "120/120 [==============================] - 0s 112us/sample - loss: 0.0538 - val_loss: 0.0356\n",
            "Epoch 895/1000\n",
            "120/120 [==============================] - 0s 110us/sample - loss: 0.0536 - val_loss: 0.0360\n",
            "Epoch 896/1000\n",
            "120/120 [==============================] - 0s 120us/sample - loss: 0.0536 - val_loss: 0.0365\n",
            "Epoch 897/1000\n",
            "120/120 [==============================] - 0s 105us/sample - loss: 0.0543 - val_loss: 0.0373\n",
            "Epoch 898/1000\n",
            "120/120 [==============================] - 0s 103us/sample - loss: 0.0540 - val_loss: 0.0374\n",
            "Epoch 899/1000\n",
            "120/120 [==============================] - 0s 116us/sample - loss: 0.0540 - val_loss: 0.0367\n",
            "Epoch 900/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0541 - val_loss: 0.0359\n",
            "Epoch 901/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0537 - val_loss: 0.0358\n",
            "Epoch 902/1000\n",
            "120/120 [==============================] - 0s 72us/sample - loss: 0.0536 - val_loss: 0.0356\n",
            "Epoch 903/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0537 - val_loss: 0.0353\n",
            "Epoch 904/1000\n",
            "120/120 [==============================] - 0s 110us/sample - loss: 0.0536 - val_loss: 0.0352\n",
            "Epoch 905/1000\n",
            "120/120 [==============================] - 0s 107us/sample - loss: 0.0539 - val_loss: 0.0354\n",
            "Epoch 906/1000\n",
            "120/120 [==============================] - 0s 107us/sample - loss: 0.0536 - val_loss: 0.0354\n",
            "Epoch 907/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0536 - val_loss: 0.0354\n",
            "Epoch 908/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0537 - val_loss: 0.0356\n",
            "Epoch 909/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0535 - val_loss: 0.0356\n",
            "Epoch 910/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0537 - val_loss: 0.0353\n",
            "Epoch 911/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0535 - val_loss: 0.0353\n",
            "Epoch 912/1000\n",
            "120/120 [==============================] - 0s 103us/sample - loss: 0.0535 - val_loss: 0.0355\n",
            "Epoch 913/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0535 - val_loss: 0.0357\n",
            "Epoch 914/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0538 - val_loss: 0.0359\n",
            "Epoch 915/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0535 - val_loss: 0.0355\n",
            "Epoch 916/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0537 - val_loss: 0.0352\n",
            "Epoch 917/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0535 - val_loss: 0.0353\n",
            "Epoch 918/1000\n",
            "120/120 [==============================] - 0s 123us/sample - loss: 0.0535 - val_loss: 0.0353\n",
            "Epoch 919/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0534 - val_loss: 0.0353\n",
            "Epoch 920/1000\n",
            "120/120 [==============================] - 0s 71us/sample - loss: 0.0534 - val_loss: 0.0352\n",
            "Epoch 921/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0534 - val_loss: 0.0350\n",
            "Epoch 922/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0545 - val_loss: 0.0347\n",
            "Epoch 923/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0542 - val_loss: 0.0352\n",
            "Epoch 924/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0534 - val_loss: 0.0352\n",
            "Epoch 925/1000\n",
            "120/120 [==============================] - 0s 120us/sample - loss: 0.0534 - val_loss: 0.0355\n",
            "Epoch 926/1000\n",
            "120/120 [==============================] - 0s 126us/sample - loss: 0.0542 - val_loss: 0.0351\n",
            "Epoch 927/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0533 - val_loss: 0.0353\n",
            "Epoch 928/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0534 - val_loss: 0.0355\n",
            "Epoch 929/1000\n",
            "120/120 [==============================] - 0s 86us/sample - loss: 0.0534 - val_loss: 0.0353\n",
            "Epoch 930/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0536 - val_loss: 0.0350\n",
            "Epoch 931/1000\n",
            "120/120 [==============================] - 0s 90us/sample - loss: 0.0533 - val_loss: 0.0350\n",
            "Epoch 932/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0533 - val_loss: 0.0350\n",
            "Epoch 933/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0532 - val_loss: 0.0352\n",
            "Epoch 934/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0532 - val_loss: 0.0354\n",
            "Epoch 935/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0533 - val_loss: 0.0354\n",
            "Epoch 936/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0534 - val_loss: 0.0350\n",
            "Epoch 937/1000\n",
            "120/120 [==============================] - 0s 73us/sample - loss: 0.0532 - val_loss: 0.0348\n",
            "Epoch 938/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0532 - val_loss: 0.0347\n",
            "Epoch 939/1000\n",
            "120/120 [==============================] - 0s 117us/sample - loss: 0.0536 - val_loss: 0.0345\n",
            "Epoch 940/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0533 - val_loss: 0.0348\n",
            "Epoch 941/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0532 - val_loss: 0.0351\n",
            "Epoch 942/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0531 - val_loss: 0.0350\n",
            "Epoch 943/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0537 - val_loss: 0.0352\n",
            "Epoch 944/1000\n",
            "120/120 [==============================] - 0s 104us/sample - loss: 0.0536 - val_loss: 0.0351\n",
            "Epoch 945/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0530 - val_loss: 0.0345\n",
            "Epoch 946/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0531 - val_loss: 0.0342\n",
            "Epoch 947/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0541 - val_loss: 0.0337\n",
            "Epoch 948/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0533 - val_loss: 0.0337\n",
            "Epoch 949/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0537 - val_loss: 0.0340\n",
            "Epoch 950/1000\n",
            "120/120 [==============================] - 0s 114us/sample - loss: 0.0531 - val_loss: 0.0342\n",
            "Epoch 951/1000\n",
            "120/120 [==============================] - 0s 104us/sample - loss: 0.0531 - val_loss: 0.0344\n",
            "Epoch 952/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0531 - val_loss: 0.0346\n",
            "Epoch 953/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0530 - val_loss: 0.0345\n",
            "Epoch 954/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0537 - val_loss: 0.0348\n",
            "Epoch 955/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0530 - val_loss: 0.0344\n",
            "Epoch 956/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0534 - val_loss: 0.0340\n",
            "Epoch 957/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0532 - val_loss: 0.0339\n",
            "Epoch 958/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0533 - val_loss: 0.0342\n",
            "Epoch 959/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0531 - val_loss: 0.0344\n",
            "Epoch 960/1000\n",
            "120/120 [==============================] - 0s 82us/sample - loss: 0.0530 - val_loss: 0.0345\n",
            "Epoch 961/1000\n",
            "120/120 [==============================] - 0s 75us/sample - loss: 0.0529 - val_loss: 0.0343\n",
            "Epoch 962/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0531 - val_loss: 0.0340\n",
            "Epoch 963/1000\n",
            "120/120 [==============================] - 0s 94us/sample - loss: 0.0529 - val_loss: 0.0340\n",
            "Epoch 964/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0531 - val_loss: 0.0343\n",
            "Epoch 965/1000\n",
            "120/120 [==============================] - 0s 103us/sample - loss: 0.0532 - val_loss: 0.0345\n",
            "Epoch 966/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0529 - val_loss: 0.0342\n",
            "Epoch 967/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0528 - val_loss: 0.0339\n",
            "Epoch 968/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0530 - val_loss: 0.0339\n",
            "Epoch 969/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0528 - val_loss: 0.0337\n",
            "Epoch 970/1000\n",
            "120/120 [==============================] - 0s 79us/sample - loss: 0.0528 - val_loss: 0.0336\n",
            "Epoch 971/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0529 - val_loss: 0.0336\n",
            "Epoch 972/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0536 - val_loss: 0.0339\n",
            "Epoch 973/1000\n",
            "120/120 [==============================] - 0s 110us/sample - loss: 0.0532 - val_loss: 0.0335\n",
            "Epoch 974/1000\n",
            "120/120 [==============================] - 0s 78us/sample - loss: 0.0529 - val_loss: 0.0335\n",
            "Epoch 975/1000\n",
            "120/120 [==============================] - 0s 83us/sample - loss: 0.0528 - val_loss: 0.0337\n",
            "Epoch 976/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0529 - val_loss: 0.0337\n",
            "Epoch 977/1000\n",
            "120/120 [==============================] - 0s 111us/sample - loss: 0.0527 - val_loss: 0.0340\n",
            "Epoch 978/1000\n",
            "120/120 [==============================] - 0s 95us/sample - loss: 0.0533 - val_loss: 0.0346\n",
            "Epoch 979/1000\n",
            "120/120 [==============================] - 0s 91us/sample - loss: 0.0529 - val_loss: 0.0343\n",
            "Epoch 980/1000\n",
            "120/120 [==============================] - 0s 92us/sample - loss: 0.0528 - val_loss: 0.0343\n",
            "Epoch 981/1000\n",
            "120/120 [==============================] - 0s 97us/sample - loss: 0.0528 - val_loss: 0.0342\n",
            "Epoch 982/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0533 - val_loss: 0.0335\n",
            "Epoch 983/1000\n",
            "120/120 [==============================] - 0s 70us/sample - loss: 0.0533 - val_loss: 0.0332\n",
            "Epoch 984/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0531 - val_loss: 0.0332\n",
            "Epoch 985/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0528 - val_loss: 0.0334\n",
            "Epoch 986/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0526 - val_loss: 0.0339\n",
            "Epoch 987/1000\n",
            "120/120 [==============================] - 0s 81us/sample - loss: 0.0527 - val_loss: 0.0345\n",
            "Epoch 988/1000\n",
            "120/120 [==============================] - 0s 88us/sample - loss: 0.0533 - val_loss: 0.0351\n",
            "Epoch 989/1000\n",
            "120/120 [==============================] - 0s 89us/sample - loss: 0.0529 - val_loss: 0.0348\n",
            "Epoch 990/1000\n",
            "120/120 [==============================] - 0s 84us/sample - loss: 0.0528 - val_loss: 0.0342\n",
            "Epoch 991/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0527 - val_loss: 0.0338\n",
            "Epoch 992/1000\n",
            "120/120 [==============================] - 0s 85us/sample - loss: 0.0526 - val_loss: 0.0330\n",
            "Epoch 993/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0536 - val_loss: 0.0326\n",
            "Epoch 994/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0532 - val_loss: 0.0325\n",
            "Epoch 995/1000\n",
            "120/120 [==============================] - 0s 74us/sample - loss: 0.0529 - val_loss: 0.0327\n",
            "Epoch 996/1000\n",
            "120/120 [==============================] - 0s 67us/sample - loss: 0.0526 - val_loss: 0.0330\n",
            "Epoch 997/1000\n",
            "120/120 [==============================] - 0s 87us/sample - loss: 0.0535 - val_loss: 0.0340\n",
            "Epoch 998/1000\n",
            "120/120 [==============================] - 0s 76us/sample - loss: 0.0526 - val_loss: 0.0342\n",
            "Epoch 999/1000\n",
            "120/120 [==============================] - 0s 77us/sample - loss: 0.0531 - val_loss: 0.0347\n",
            "Epoch 1000/1000\n",
            "120/120 [==============================] - 0s 80us/sample - loss: 0.0527 - val_loss: 0.0342\n",
            "Time passed 13.44818663597107 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEjCAYAAAA/ugbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CThcAHOpTP_A",
        "colab_type": "code",
        "outputId": "992db1fe-e220-4721-fd40-2a6594044b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "train_sa_iris(k_max = 1000,annealing_rate = 0.95, decay_freq=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K 0,Accuracy: 0.3416666666666667, Loss current:1.1926043296853701 neighbour:3.582847421305875, validation_loss 1.2149014631907145, p_model 0.36787944117144233, p_neighbour 0.049577341372262024, alpha 0.13476518615553068\n",
            "K 100,Accuracy: 0.5583333333333333, Loss current:2.3417376835356665 neighbour:3.4736419337547733, validation_loss 2.4727351799729758, p_model 0.12657829200321954, p_neighbour 0.04660954376052392, alpha 0.36822699234508866\n",
            "K 200,Accuracy: 0.5166666666666667, Loss current:2.714793364096598 neighbour:2.748715883353725, validation_loss 2.3053912829256054, p_model 0.08027641889554933, p_neighbour 0.07778580362422072, alpha 0.9689745095060949\n",
            "K 300,Accuracy: 0.675, Loss current:2.326934501421541 neighbour:11.999396706620871, validation_loss 2.6251462621672546, p_model 0.10272392513778492, p_neighbour 8.006583357873767e-06, alpha 7.794273191113399e-05\n",
            "K 400,Accuracy: 0.425, Loss current:1.4681152468905965 neighbour:8.79955090705378, validation_loss 1.201380096127654, p_model 0.2206086526981493, p_neighbour 0.0001163648729256426, alpha 0.0005274719350417338\n",
            "K 500,Accuracy: 0.575, Loss current:1.6701308832023642 neighbour:5.972844669720675, validation_loss 1.9999431232611338, p_model 0.1636831091493695, p_neighbour 0.0015454783465657714, alpha 0.009441892658303799\n",
            "K 600,Accuracy: 0.6666666666666666, Loss current:1.1716187885986662 neighbour:2.8030541328265843, validation_loss 0.7674320400600626, p_model 0.26278043157340025, p_neighbour 0.040869376431442284, alpha 0.15552671173700613\n",
            "K 700,Accuracy: 0.6333333333333333, Loss current:2.0873982868197305 neighbour:2.398856227214743, validation_loss 1.5606556065525297, p_model 0.08156447551955048, p_neighbour 0.05611610994616314, alpha 0.6879969446099419\n",
            "K 800,Accuracy: 0.7583333333333333, Loss current:1.4605336569296166 neighbour:1.8851996826193151, validation_loss 2.415486042659495, p_model 0.15787096542017895, p_neighbour 0.09229962571152785, alpha 0.5846523169467498\n",
            "K 900,Accuracy: 0.6666666666666666, Loss current:0.7652385770470578 neighbour:4.720657283811965, validation_loss 0.7042230642303688, p_model 0.3612827640395792, p_neighbour 0.0018724797556322818, alpha 0.005182864897001142\n",
            "Time passed 17.166504859924316 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEjCAYAAAA41BqSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCFkKjr4EELIVHTwIYSQqX8Aof4iMZBiM3UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMRiuagY_nxy",
        "colab_type": "code",
        "outputId": "df2a4f2f-17f4-4a49-9684-5bf8606c40b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "train_sa_iris(k_max = 1000,annealing_rate = 0.90, decay_freq=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K 0,Accuracy: 0.3333333333333333, Loss current:1.335454242428144 neighbour:1.8404881657411656, validation_loss 1.3170674781004588, p_model 0.36787944117144233, p_neighbour 0.2520383833582759, alpha 0.6851113575569959\n",
            "K 100,Accuracy: 0.39166666666666666, Loss current:4.807542539500312 neighbour:1.8693825822438745, validation_loss 3.385542000834488, p_model 0.018317052085853533, p_neighbour 0.21111658555970683, alpha 11.525685714610953\n",
            "K 200,Accuracy: 0.7583333333333333, Loss current:1.658564163471499 neighbour:2.346931792057997, validation_loss 2.353662879871513, p_model 0.21582905077227327, p_neighbour 0.11421943691235202, alpha 0.5292125249295928\n",
            "K 300,Accuracy: 0.45, Loss current:3.6777455858368624 neighbour:5.991916758926558, validation_loss 3.8398987306359533, p_model 0.02287570639244247, p_neighbour 0.0021234074511385843, alpha 0.09282368879503114\n",
            "K 400,Accuracy: 0.6666666666666666, Loss current:4.822675106508238 neighbour:4.283090323504406, validation_loss 4.48159670393652, p_model 0.004069913808658111, p_neighbour 0.007534191607161474, alpha 1.8511919321568062\n",
            "K 500,Accuracy: 0.6666666666666666, Loss current:4.767209936960745 neighbour:8.555132065883232, validation_loss 5.922885202316047, p_model 0.002368809762653708, p_neighbour 1.942623025996819e-05, alpha 0.008200840171397114\n",
            "K 600,Accuracy: 0.75, Loss current:2.8633149897621566 neighbour:2.2114937283766154, validation_loss 5.293381034148236, p_model 0.017695291454474432, p_neighbour 0.04433281664755128, alpha 2.5053453774191032\n",
            "K 700,Accuracy: 0.6083333333333333, Loss current:0.8496315552477824 neighbour:1.0443499263974163, validation_loss 1.0526407020558508, p_model 0.2644348092127615, p_neighbour 0.19495111970214024, alpha 0.7372369783029759\n",
            "K 800,Accuracy: 0.5, Loss current:0.8587646084363143 neighbour:0.9271753055526043, validation_loss 0.8471135937912606, p_model 0.22450813797669067, p_neighbour 0.19931964110805078, alpha 0.887805862648707\n",
            "K 900,Accuracy: 0.7, Loss current:0.43632451323271726 neighbour:2.7361610397099616, validation_loss 0.3683059489354491, p_model 0.43027492902330183, p_neighbour 0.005049479284499821, alpha 0.011735471773737398\n",
            "Time passed 17.39250087738037 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEjCAYAAAA1ymrVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBKHF+P9th8XypeFHIAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KeH-HJ4_pHg",
        "colab_type": "code",
        "outputId": "a2fa406c-c224-4554-bb67-71b53d06fa24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "train_sa_iris(k_max = 1000,annealing_rate = 0.80, decay_freq=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K 0,Accuracy: 0.3333333333333333, Loss current:1.190190433462461 neighbour:1.3026584486166637, validation_loss 1.2267445663611094, p_model 0.36787944117144233, p_neighbour 0.3347083192888086, alpha 0.9098315421568366\n",
            "K 100,Accuracy: 0.3333333333333333, Loss current:2.4832168117922264 neighbour:2.7258452837044995, validation_loss 2.4619741938464963, p_model 0.07368148983703694, p_neighbour 0.057107219823211534, alpha 0.7750551726019235\n",
            "K 200,Accuracy: 0.6666666666666666, Loss current:1.0487162941828576 neighbour:12.120501116980257, validation_loss 1.191319485426478, p_model 0.2523923114677084, p_neighbour 1.2288988067254932e-07, alpha 4.86900254440881e-07\n",
            "K 300,Accuracy: 0.7416666666666667, Loss current:1.0421353375816882 neighbour:6.079776389422962, validation_loss 1.0623517752896683, p_model 0.1808361712320416, p_neighbour 4.645492902457387e-05, alpha 0.00025688958524212944\n",
            "K 400,Accuracy: 0.5916666666666667, Loss current:1.1062694366516947 neighbour:7.211496441141446, validation_loss 1.0712425504716216, p_model 0.1033885226796906, p_neighbour 3.763476658853339e-07, alpha 3.6401300273077866e-06\n",
            "K 500,Accuracy: 0.6666666666666666, Loss current:0.7400124096224318 neighbour:7.508692267745499, validation_loss 0.8303363948594779, p_model 0.14994901742221922, p_neighbour 4.350486978021222e-09, alpha 2.901310760690969e-08\n",
            "K 600,Accuracy: 0.7333333333333333, Loss current:1.929863672208854 neighbour:4.688322660479603, validation_loss 2.5059157321663066, p_model 0.002059205413718237, p_neighbour 2.9786856685960397e-07, alpha 0.00014465218713744193\n",
            "K 700,Accuracy: 0.6416666666666667, Loss current:1.449680726015154 neighbour:3.25193136535122, validation_loss 0.9791524615275979, p_model 0.0030034553098357416, p_neighbour 2.1967804887668213e-06, alpha 0.0007314177379542774\n",
            "K 800,Accuracy: 0.9166666666666666, Loss current:0.498394991754445 neighbour:8.91586993472187, validation_loss 0.5317871835184633, p_model 0.08241743615405071, p_neighbour 4.059639775248853e-20, alpha 4.925705002107526e-19\n",
            "K 900,Accuracy: 0.5583333333333333, Loss current:1.1314600953663718 neighbour:13.98363877584537, validation_loss 1.152424910531652, p_model 0.0008393109933452474, p_neighbour 9.615488644591293e-39, alpha 1.1456407363695757e-35\n",
            "Time passed 17.009103775024414 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEjCAYAAAA41BqSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI6H8fxA+XN/2B6NuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M5wbixL_qiT",
        "colab_type": "code",
        "outputId": "9c05b6fd-9b7b-4eac-d21a-8b2f9549b7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "train_sa_iris(k_max = 1000,annealing_rate = 0.60, decay_freq=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K 0,Accuracy: 0.3416666666666667, Loss current:1.1489223261674246 neighbour:1.3201296503034732, validation_loss 1.1819266696770987, p_model 0.36787944117144233, p_neighbour 0.3169486271588536, alpha 0.8615556937609526\n",
            "K 100,Accuracy: 0.30833333333333335, Loss current:2.4527399437502027 neighbour:6.85273190671578, validation_loss 2.1068430906782547, p_model 0.028494909328019607, p_neighbour 4.8168218219106464e-05, alpha 0.001690414861988759\n",
            "K 200,Accuracy: 0.8083333333333333, Loss current:0.746304404369251 neighbour:2.6764044329557994, validation_loss 0.518771222655414, p_model 0.16457999723037922, p_neighbour 0.0015479731455303371, alpha 0.00940559710523924\n",
            "K 300,Accuracy: 0.9416666666666667, Loss current:0.13532962564536888 neighbour:3.351808973474711, validation_loss 0.3947064262098498, p_model 0.5796584221285334, p_neighbour 1.3624149784652966e-06, alpha 2.3503755426556967e-06\n",
            "K 400,Accuracy: 0.825, Loss current:0.3344179309977335 neighbour:5.1872592427974835, validation_loss 0.2945454881271265, p_model 0.10583034930528547, p_neighbour 7.420440445046074e-16, alpha 7.011637487504235e-15\n",
            "Time passed 7.078758239746094 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEjCAYAAAA/ugbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}